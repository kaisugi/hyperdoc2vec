Following up on numerous reports of analogybased identification of “linguistic regularities”
in word embeddings, this study applies the
widely used vector offset method to 4 types
of linguistic relations: inflectional and derivational morphology, and lexicographic and encyclopedic semantics. We present a balanced
test set with 99,200 questions in 40 categories,
and we systematically examine how accuracy
for different categories is affected by window
size and dimensionality of the SVD-based
word embeddings. We also show that GloVe
and SVD yield similar patterns of results for
different categories, offering further evidence
for conceptual similarity between count-based
and neural-net based models.